{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dricvwp99sjA"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV\n",
        "df = pd.read_csv(\"/content/poems-100.csv\")\n",
        "\n",
        "# Ignore first row and extract poems\n",
        "poems = df.iloc[:, 0].astype(str).tolist()\n",
        "\n",
        "# Combine all poems into one text corpus\n",
        "text_data = \" \".join(poems).lower()\n",
        "\n",
        "print(\"Number of poems:\", len(poems))\n",
        "print(\"Sample text:\\n\", text_data[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IInoq4Yj91Ms",
        "outputId": "e849699e-6cb3-4c80-e945-88b685660937"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of poems: 100\n",
            "Sample text:\n",
            " o my luve's like a red, red rose\n",
            "that’s newly sprung in june;\n",
            "o my luve's like the melodie\n",
            "that’s sweetly play'd in tune.\n",
            "\n",
            "as fair art thou, my bonnie lass,\n",
            "so deep in luve am i:\n",
            "and i will luve thee still, my dear,\n",
            "till a’ the seas gang dry:\n",
            "\n",
            "till a’ the seas gang dry, my dear,\n",
            "and the rocks melt wi’ the sun:\n",
            "i will luve thee still, my dear,\n",
            "while the sands o’ life shall run.\n",
            "\n",
            "and fare thee well, my only luve\n",
            "and fare thee well, a while!\n",
            "and i will come again, my luve,\n",
            "tho’ it were ten thousand\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple whitespace tokenization\n",
        "tokens = text_data.split()\n",
        "\n",
        "# Build vocabulary\n",
        "word_counts = Counter(tokens)\n",
        "vocab = sorted(word_counts.keys())\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Word to index mapping\n",
        "word2idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx2word = {i: word for word, i in word2idx.items()}\n",
        "\n",
        "print(\"Vocabulary size:\", vocab_size)\n",
        "print(\"Sample vocab words:\", vocab[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OQ72oDz-GRZ",
        "outputId": "cb8c85e6-257e-4c28-e64f-8b727bea263a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 6989\n",
            "Sample vocab words: ['\"he', '\"most', '\"oh,', \"'greatly\", \"'neath\", \"'our\", \"'s\", \"'tis\", \"'twas\", \"'twere\", \"'twill\", \"('tis\", '(1)', '(and', '(as', '(behind', '(come', '(even', '(floating', '(for']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SimpleRNN:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
        "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
        "        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n",
        "\n",
        "        self.bh = np.zeros((hidden_size, 1))\n",
        "        self.by = np.zeros((output_size, 1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        h = np.zeros((self.hidden_size, 1))\n",
        "        outputs = []\n",
        "\n",
        "        for x in inputs:\n",
        "            h = np.tanh(np.dot(self.Wxh, x) + np.dot(self.Whh, h) + self.bh)\n",
        "            y = np.dot(self.Why, h) + self.by\n",
        "            outputs.append(y)\n",
        "\n",
        "        return outputs, h\n",
        ""
      ],
      "metadata": {
        "id": "X5CefIpg-gm_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sequence_length = 5\n",
        "\n",
        "def create_sequences(tokens, seq_length):\n",
        "    sequences = []\n",
        "    for i in range(len(tokens) - seq_length):\n",
        "        seq = tokens[i:i+seq_length]\n",
        "        target = tokens[i+seq_length]\n",
        "        sequences.append((seq, target))\n",
        "    return sequences\n",
        "\n",
        "sequences = create_sequences(tokens, sequence_length)\n",
        "print(\"Total sequences:\", len(sequences))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9yQKUU7-pFx",
        "outputId": "6d0d3333-9731-40a7-94e8-c7846b25312a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sequences: 24729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(word, vocab_size):\n",
        "    vec = np.zeros(vocab_size)\n",
        "    vec[word2idx[word]] = 1\n",
        "    return vec"
      ],
      "metadata": {
        "id": "6sWaCjly-riq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OneHotDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq, target = self.sequences[idx]\n",
        "\n",
        "        x = [one_hot_encode(word, vocab_size) for word in seq]\n",
        "        x = torch.tensor(x, dtype=torch.float32)\n",
        "\n",
        "        y = torch.tensor(word2idx[target], dtype=torch.long)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "dataset_onehot = OneHotDataset(sequences)\n",
        "loader_onehot = torch.utils.data.DataLoader(dataset_onehot, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "QVs25Sac-vfV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_OneHot(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN_OneHot, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "2V-War3V-4h3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFvgWzUp-7H7",
        "outputId": "f9ce6e7b-35f6-4841-ef11-0ed319b62ab7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_onehot = RNN_OneHot(vocab_size, 128, vocab_size).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_onehot.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 10\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x, y in loader_onehot:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model_onehot(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader_onehot):.4f}\")\n",
        "\n",
        "print(\"Training Time:\", time.time() - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afkrIK-y-9f8",
        "outputId": "a21c90b2-aca9-4bc1-bd6d-0187c1665748"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-76012416.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  x = torch.tensor(x, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.2562\n",
            "Epoch 2, Loss: 6.4333\n",
            "Epoch 3, Loss: 5.7067\n",
            "Epoch 4, Loss: 4.8471\n",
            "Epoch 5, Loss: 3.9490\n",
            "Epoch 6, Loss: 3.0981\n",
            "Epoch 7, Loss: 2.3498\n",
            "Epoch 8, Loss: 1.7197\n",
            "Epoch 9, Loss: 1.2370\n",
            "Epoch 10, Loss: 0.8921\n",
            "Training Time: 1184.5059220790863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_onehot(model, start_text, length=20):\n",
        "    model.eval()\n",
        "    words = start_text.lower().split()\n",
        "\n",
        "    for _ in range(length):\n",
        "        seq = words[-sequence_length:]\n",
        "        x = [one_hot_encode(word, vocab_size) for word in seq]\n",
        "        x = torch.tensor([x], dtype=torch.float32).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(x)\n",
        "            predicted = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        next_word = idx2word[predicted]\n",
        "        words.append(next_word)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(generate_text_onehot(model_onehot, \"the night was\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCFx9YSA_Aeu",
        "outputId": "ac67ebc1-3476-4729-a691-fd9041b3a441"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the night was shine men, the lips. that hangs blood the wife's or altamahaw, twelve by the supper with night, light sings and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IndexedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq, target = self.sequences[idx]\n",
        "        x = torch.tensor([word2idx[word] for word in seq], dtype=torch.long)\n",
        "        y = torch.tensor(word2idx[target], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "dataset_embed = IndexedDataset(sequences)\n",
        "loader_embed = torch.utils.data.DataLoader(dataset_embed, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "ir1DIGoTDql7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RNN_Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size):\n",
        "        super(RNN_Embedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "wduGHDXoDuCU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_embed = RNN_Embedding(vocab_size, 100, 128).to(device)\n",
        "optimizer = optim.Adam(model_embed.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x, y in loader_embed:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model_embed(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader_embed):.4f}\")\n",
        "\n",
        "print(\"Training Time:\", time.time() - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7FxboiPDwdV",
        "outputId": "25553d8e-0dce-4065-b82f-7e48e28c492a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 7.3467\n",
            "Epoch 2, Loss: 6.4326\n",
            "Epoch 3, Loss: 5.9048\n",
            "Epoch 4, Loss: 5.3831\n",
            "Epoch 5, Loss: 4.8532\n",
            "Epoch 6, Loss: 4.3287\n",
            "Epoch 7, Loss: 3.8164\n",
            "Epoch 8, Loss: 3.3375\n",
            "Epoch 9, Loss: 2.9092\n",
            "Epoch 10, Loss: 2.5275\n",
            "Training Time: 73.1105010509491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_embedding(model, start_text, length=20):\n",
        "    model.eval()\n",
        "    words = start_text.lower().split()\n",
        "\n",
        "    for _ in range(length):\n",
        "        seq = words[-sequence_length:]\n",
        "        x = torch.tensor([[word2idx[word] for word in seq]], dtype=torch.long).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(x)\n",
        "            predicted = torch.argmax(output, dim=1).item()\n",
        "\n",
        "        next_word = idx2word[predicted]\n",
        "        words.append(next_word)\n",
        "\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(generate_text_embedding(model_embed, \"the night was\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_0SNwWRDzKR",
        "outputId": "c51f3b73-5334-4a44-c583-02cbb69d2af2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the night was the reason of the stairs, of the earth, and of the house of the stairs, of the earth, and of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t306L_ufEghn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}